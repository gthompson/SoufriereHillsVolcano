{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge catalogs\n",
    "Reconcile full catalog on hal/newton in Fall 2021 with the incomplete but partially reclassified catalog from my laptop whilst in Paris in July 2021\n",
    "Need to reconcile reawav_MVOE_all.csv (concatenated reawav_MVOE_YYYYMM.csv) on hal9000 against catalog_unique.csv which came from processing in Paris \n",
    "on my laptop.\n",
    "\n",
    "Need to merge the new_subclass, weight, checked, split, delete and ignore columns.\n",
    "Should probably match on the WAVfile path.\n",
    "Do I need to merge D, R, r, e, l, h and t columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Concatenate the catalog YYYYMM CSV files into original master catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "def subset_columns(df):\n",
    "    good_columns = []\n",
    "    for thiscol in df.columns:\n",
    "        if not 'ntitle' in thiscol:\n",
    "            if not 'Unname' in thiscol:\n",
    "                if not thiscol=='index':\n",
    "                    if not 'level_0' in thiscol:\n",
    "                        good_columns.append(thiscol)\n",
    "    df2 = df[good_columns] # subset to correct columns   \n",
    "    #df2.set_index('path', inplace=True)\n",
    "    #df2.sort_index(inplace=True)     \n",
    "    return df2\n",
    "\n",
    "def df2csv_without_index(df, csvfile):\n",
    "    #df = df.reset_index()  \n",
    "    #print(df.head())\n",
    "    print(df.columns)\n",
    "    df.drop(df.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    df.to_csv(csvfile, index=False)\n",
    "\n",
    "def _df2file_without_index(df, catfile, indexcol=None):\n",
    "    if not 'path' in df.columns:\n",
    "        df = df.reset_index()  \n",
    "    if indexcol:\n",
    "        if not indexcol in df.columns:\n",
    "            df.rename(columns = {'index':indexcol})\n",
    "    df.drop(df.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    if catfile[-3:]=='csv':\n",
    "        df.to_csv(catfile, index=False)\n",
    "    if catfile[-3:]=='pkl':\n",
    "        df.to_pickle(catfile)  \n",
    "    \n",
    "def number_of_checked_events(df):\n",
    "    df2 = df[df['checked']==True]\n",
    "    return len(df2.index)\n",
    "\n",
    "def build_master_event_catalog(pandaSeisDBDir, SEISAN_DB, catalogfile, subclasses_for_ML, max_duration = 300):\n",
    "\n",
    "    concatfile = 'catalog_all.csv'\n",
    "    if os.path.exists(concatfile):\n",
    "        dfall = pd.read_csv(concatfile)\n",
    "    else:\n",
    "    \n",
    "        # load all the year/month CSV files\n",
    "        csvfiles = glob(os.path.join(pandaSeisDBDir, 'catalog_%s[12][0-9][0-9][0-9][0-1][0-9].csv' % SEISAN_DB))\n",
    "        frames = []\n",
    "        if len(csvfiles)==0:\n",
    "            print('No *.csv files found. Cannot proceed')\n",
    "            exit()\n",
    "        for csvfile in csvfiles:\n",
    "            df = pd.read_csv(csvfile)\n",
    "            frames.append(df) \n",
    "        dfall = pd.concat(frames, sort=True)\n",
    "        _df2file_without_index(dfall.copy(), concatfile)\n",
    "        \n",
    "    print(dfall.columns)\n",
    "\n",
    "    # replace loop above\n",
    "    for mainclass in ['R', 'D']:\n",
    "        dfall.loc[dfall['mainclass'] == mainclass, 'subclass'] = mainclass\n",
    "    \n",
    "    # Drop the mainclass column, as it is now superfluous.\n",
    "    dfall.drop(columns=['mainclass'], inplace=True)\n",
    "    \n",
    "    # Add columns to assign a percentage for each subclass\n",
    "    for subclass in subclasses_for_ML:\n",
    "        dfall[subclass] = 0\n",
    "    \n",
    "    # But set column for actual subclass to 100%  \n",
    "    for subclass in subclasses_for_ML:\n",
    "        dfall.loc[dfall['subclass'] == subclass, subclass] = 100\n",
    "        \n",
    "    # Add a new_subclass column\n",
    "    dfall['new_subclass'] = dfall['subclass']\n",
    "\n",
    "    # Add weight column. I will give really clear events higher weight when I process them\n",
    "    dfall['weight']=3 # weight for events I have not visually checked\n",
    "    \n",
    "    # Add column that records if event is checked\n",
    "    dfall['checked']=False\n",
    "    \n",
    "    # Add column that records if event is marked for splitting\n",
    "    dfall['split']=False    \n",
    "    \n",
    "    # Add column that records if event is marked for deletion\n",
    "    dfall['delete']=False\n",
    "    \n",
    "    # Add column that records if event should be ignored\n",
    "    # Ignore any events longer than 1-minute, as they are likely to contain multiple events \n",
    "    # or just be unhelpful for classifying short signals which are more common\n",
    "    # SCAFFOLD - the twin column no longer seems to exist\n",
    "    #dfall['ignore'] = dfall['twin']>max_duration\n",
    "    dfall['ignore'] = False\n",
    "    \n",
    "    # Now we have a catalog dataframe we can work with. Let's save this.\n",
    "    #dfall2 = dfall.reset_index()    \n",
    "    #dfall2.to_csv(catalogfile)\n",
    "    _df2file_without_index(dfall.copy(), catalogfile)\n",
    "    \n",
    "    return dfall\n",
    "\n",
    "def summarize_df(df):\n",
    "    print('Events: %d. Checked: %d ' % (len(df.index), number_of_checked_events(df)) )\n",
    "    print(df.columns)\n",
    "    dfhead = df.head()\n",
    "    print(dfhead[['path','DSN_wavfile']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events: 231951. Checked: 0 \n",
      "Index(['index', 'ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile',\n",
      "       'Eseismic', 'Fs', 'R', 'bandratio_[0.8_4.0_16.0]',\n",
      "       'bandratio_[1.0_6.0_11.0]', 'bw_max', 'bw_min', 'calib',\n",
      "       'corrected_ASN_mseed', 'corrected_DSN_mseed', 'day', 'elev', 'energy',\n",
      "       'filetime', 'hour', 'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF',\n",
      "       'minute', 'month', 'noise_level', 'num_gaps', 'num_traces', 'path',\n",
      "       'peakA', 'peakF', 'peakamp', 'peaktime', 'percent_availability',\n",
      "       'quality', 'sample_lower_quartile', 'sample_max', 'sample_mean',\n",
      "       'sample_median', 'sample_min', 'sample_rms', 'sample_stdev',\n",
      "       'sample_upper_quartile', 'second', 'sfile', 'signal_level', 'skewness',\n",
      "       'snr', 'subclass', 'twin', 'year', 'D', 'r', 'e', 'l', 'h', 't',\n",
      "       'new_subclass', 'weight', 'checked', 'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n",
      "                        path                DSN_wavfile\n",
      "0  9801-01-0002-04S.MVO_18_1  9801-01-0002-04S.MVO_18_1\n",
      "1  9801-01-0104-32S.MVO_18_1  9801-01-0104-32S.MVO_18_1\n",
      "2  9801-01-0121-09S.MVO_18_1  9801-01-0121-09S.MVO_18_1\n",
      "3  9801-01-0200-27S.MVO_18_1  9801-01-0200-27S.MVO_18_1\n",
      "4  9801-01-0221-36S.MVO_18_1  9801-01-0221-36S.MVO_18_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/miniconda3/envs/AAA/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "SEISAN_DATA = os.path.join( os.getenv('HOME'),'DATA','MVO') # e.g. /home/user/seismo\n",
    "pandaSeisDir = os.path.join(SEISAN_DATA, 'miniseed_c') # e.g. /home/user/seismo/pandaSeis\n",
    "SEISAN_DB = 'MVOE_' # e.g. the seisan database name (e.g. MVOE_) under /home/user/seismo/WAV and /home/user/seismo/REA\n",
    "pandaSeisDBDir = os.path.join(pandaSeisDir, SEISAN_DB) # e.g. /home/user/seismo/pandaSeis/MVOE_\n",
    "AAA_DATA_DIR = os.path.join(SEISAN_DATA, 'MachineLearning', SEISAN_DB) # e.g. /home/user/seismo/MachineLearning/MVOE_\n",
    "master_event_catalog_original = os.path.join(AAA_DATA_DIR, 'original', '%s11_master_catalog_rebuilt.csv' % SEISAN_DB)\n",
    "subclasses_for_ML = ['D', 'R', 'r', 'e', 'l', 'h', 't'] # subclasses allowed for Machine Learning # add g here?\n",
    "\n",
    "if os.path.exists(master_event_catalog_original):\n",
    "    dfall = pd.read_csv(master_event_catalog_original)\n",
    "else:\n",
    "    dfall = build_master_event_catalog(pandaSeisDBDir, SEISAN_DB, master_event_catalog_original, subclasses_for_ML)\n",
    "\n",
    "summarize_df(dfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events: 231951. Checked: 0 \n",
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'path', 'peakA', 'peakF',\n",
      "       'peakamp', 'peaktime', 'percent_availability', 'quality',\n",
      "       'sample_lower_quartile', 'sample_max', 'sample_mean', 'sample_median',\n",
      "       'sample_min', 'sample_rms', 'sample_stdev', 'sample_upper_quartile',\n",
      "       'second', 'sfile', 'signal_level', 'skewness', 'snr', 'subclass',\n",
      "       'twin', 'year', 'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight',\n",
      "       'checked', 'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n",
      "                        path                DSN_wavfile\n",
      "0  9801-01-0002-04S.MVO_18_1  9801-01-0002-04S.MVO_18_1\n",
      "1  9801-01-0104-32S.MVO_18_1  9801-01-0104-32S.MVO_18_1\n",
      "2  9801-01-0121-09S.MVO_18_1  9801-01-0121-09S.MVO_18_1\n",
      "3  9801-01-0200-27S.MVO_18_1  9801-01-0200-27S.MVO_18_1\n",
      "4  9801-01-0221-36S.MVO_18_1  9801-01-0221-36S.MVO_18_1\n"
     ]
    }
   ],
   "source": [
    "# ensure we always have the same index and columns\n",
    "dfall2 = subset_columns(dfall)\n",
    "summarize_df(dfall2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Remove any events without a miniseed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events: 209135. Checked: 0 \n",
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'path', 'peakA', 'peakF',\n",
      "       'peakamp', 'peaktime', 'percent_availability', 'quality',\n",
      "       'sample_lower_quartile', 'sample_max', 'sample_mean', 'sample_median',\n",
      "       'sample_min', 'sample_rms', 'sample_stdev', 'sample_upper_quartile',\n",
      "       'second', 'sfile', 'signal_level', 'skewness', 'snr', 'subclass',\n",
      "       'twin', 'year', 'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight',\n",
      "       'checked', 'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n",
      "                        path                DSN_wavfile\n",
      "0  9801-01-0002-04S.MVO_18_1  9801-01-0002-04S.MVO_18_1\n",
      "1  9801-01-0104-32S.MVO_18_1  9801-01-0104-32S.MVO_18_1\n",
      "2  9801-01-0121-09S.MVO_18_1  9801-01-0121-09S.MVO_18_1\n",
      "3  9801-01-0200-27S.MVO_18_1  9801-01-0200-27S.MVO_18_1\n",
      "4  9801-01-0221-36S.MVO_18_1  9801-01-0221-36S.MVO_18_1\n"
     ]
    }
   ],
   "source": [
    "miniseed_cat = dfall2[dfall2['corrected_DSN_mseed'].isnull()==False]\n",
    "summarize_df(miniseed_cat)\n",
    "N_miniseed_cat = number_of_checked_events(miniseed_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Examine the catalog processed in July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'R', 'checked', 'delete', 'e', 'h', 'ignore', 'l', 'new_subclass', 'path', 'quality', 'r', 'split', 'subclass', 't', 'weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/miniconda3/envs/AAA/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "some_checked_csv = \"../CSVfiles/catalog_unique.csv\"\n",
    "some_checked_cat = pd.read_csv(some_checked_csv)\n",
    "checked_cat = some_checked_cat[some_checked_cat['checked']==True]\n",
    "checked_cat = checked_cat[['path', 'quality','subclass','D', 'R',\n",
    "       'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked', 'split',\n",
    "       'delete', 'ignore']]\n",
    "#checked_cat.rename(columns={'path':'DSN_wavfile'}, inplace=True)\n",
    "N_checked_cat = number_of_checked_events(checked_cat)\n",
    "print(sorted(checked_cat.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Merge the catalogs - had to write my own code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/DATA/MVO/MachineLearning/MVOE_/original/MVOE_11_master_catalog_rebuilt.csv has 0 checked events\n",
      "../CSVfiles/catalog_unique.csv has 584 checked events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'peakA', 'peakF', 'peakamp',\n",
      "       'peaktime', 'percent_availability', 'quality', 'sample_lower_quartile',\n",
      "       'sample_max', 'sample_mean', 'sample_median', 'sample_min',\n",
      "       'sample_rms', 'sample_stdev', 'sample_upper_quartile', 'second',\n",
      "       'sfile', 'signal_level', 'skewness', 'snr', 'subclass', 'twin', 'year',\n",
      "       'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked',\n",
      "       'split', 'delete', 'ignore', 'path'],\n",
      "      dtype='object')\n",
      "Events: 209092. Checked: 584 \n",
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'peakA', 'peakF', 'peakamp',\n",
      "       'peaktime', 'percent_availability', 'quality', 'sample_lower_quartile',\n",
      "       'sample_max', 'sample_mean', 'sample_median', 'sample_min',\n",
      "       'sample_rms', 'sample_stdev', 'sample_upper_quartile', 'second',\n",
      "       'sfile', 'signal_level', 'skewness', 'snr', 'subclass', 'twin', 'year',\n",
      "       'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked',\n",
      "       'split', 'delete', 'ignore', 'path'],\n",
      "      dtype='object')\n",
      "                                                path  \\\n",
      "path                                                   \n",
      "9801-01-0002-04S.MVO_18_1  9801-01-0002-04S.MVO_18_1   \n",
      "9801-01-0104-32S.MVO_18_1  9801-01-0104-32S.MVO_18_1   \n",
      "9801-01-0121-09S.MVO_18_1  9801-01-0121-09S.MVO_18_1   \n",
      "9801-01-0200-27S.MVO_18_1  9801-01-0200-27S.MVO_18_1   \n",
      "9801-01-0221-36S.MVO_18_1  9801-01-0221-36S.MVO_18_1   \n",
      "\n",
      "                                         DSN_wavfile  \n",
      "path                                                  \n",
      "9801-01-0002-04S.MVO_18_1  9801-01-0002-04S.MVO_18_1  \n",
      "9801-01-0104-32S.MVO_18_1  9801-01-0104-32S.MVO_18_1  \n",
      "9801-01-0121-09S.MVO_18_1  9801-01-0121-09S.MVO_18_1  \n",
      "9801-01-0200-27S.MVO_18_1  9801-01-0200-27S.MVO_18_1  \n",
      "9801-01-0221-36S.MVO_18_1  9801-01-0221-36S.MVO_18_1  \n"
     ]
    }
   ],
   "source": [
    "print('%s has %d checked events' % (master_event_catalog_original, N_miniseed_cat) )\n",
    "print('%s has %d checked events' % (some_checked_csv, N_checked_cat) )\n",
    "\n",
    "# RESET INDEXES\n",
    "set_index_to_path = True\n",
    "if set_index_to_path:\n",
    "    if 'path' in miniseed_cat.columns:\n",
    "        miniseed_cat.set_index('path', inplace=True)\n",
    "        #miniseed_cat.sort_index(inplace=True)\n",
    "    if 'path' in checked_cat.columns:\n",
    "        checked_cat.set_index('path', inplace=True)\n",
    "        #checked_cat.sort_index(inplace=True)\n",
    "\n",
    "def mergeGT(miniseed, checked):\n",
    "    frames = []\n",
    "    for i2, row in checked.iterrows():\n",
    "        i2base = os.path.basename(i2)\n",
    "        subset_df = miniseed[miniseed.index == i2base]\n",
    "        if len(subset_df.index)==1:\n",
    "            for col in checked.columns:\n",
    "                subset_df.loc[i2base, col] = row[col]\n",
    "            frames.append(subset_df)   \n",
    "    newdf = pd.concat(frames)\n",
    "    newdf['path'] = newdf.index\n",
    "    combineddf = pd.concat([miniseed, newdf])\n",
    "    combineddf['path'] = combineddf.index\n",
    "    mergeddf = combineddf.drop_duplicates(subset=['path'], keep='last')\n",
    "    return mergeddf\n",
    "merged_cat = mergeGT(miniseed_cat, checked_cat)\n",
    "\n",
    "print(merged_cat.columns)\n",
    "summarize_df(merged_cat)\n",
    "N_merged_cat = number_of_checked_events(merged_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'peakA', 'peakF', 'peakamp',\n",
      "       'peaktime', 'percent_availability', 'quality', 'sample_lower_quartile',\n",
      "       'sample_max', 'sample_mean', 'sample_median', 'sample_min',\n",
      "       'sample_rms', 'sample_stdev', 'sample_upper_quartile', 'second',\n",
      "       'sfile', 'signal_level', 'skewness', 'snr', 'subclass', 'twin', 'year',\n",
      "       'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked',\n",
      "       'split', 'delete', 'ignore', 'path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "master_event_catalog = '/Users/thompsong/DATA/MVO/MachineLearning/MVOE_/labelling/11_merged_catalog.csv'\n",
    "df2csv_without_index(merged_cat, master_event_catalog)\n",
    "_df2file_without_index(merged_cat, master_event_catalog.replace('.csv','.pkl'), indexcol=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
