{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "disciplinary-marks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./AAA-master/config/specific/usecase1_continuous_classification/usecase1_EXAMPLE.json\n",
      "Welcome to this automatic analysis architecture\n",
      "Copyright: Marielle MALFANTE - GIPSA-Lab\n",
      "Univ. Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, 38000 Grenoble, France\n",
      "\n",
      " *** PROJECT CONFIGURATION 10 ***  \n",
      "Configuration object from <path> ./AAA-master/config/general/newsettings_10.json, <configuration_number> 10,\n",
      " <general> {'project_root': './AAA-master/', 'analysis_type': 'continuous', 'path_to_specific_settings_file': 'config/specific/usecase1_continuous_classification/usecase1_EXAMPLE.json', 'path_to_res': 'res/', 'path_to_visuals': 'fig/', 'path_to_res_to_review': 'res_to_review/'},\n",
      " <application> {'name': 'montserrat'},\n",
      " <preprocessing> {'energy_norm': True},\n",
      " <learning> {'algo': RandomForestClassifier(criterion='entropy'), 'cv': StratifiedShuffleSplit(n_splits=50, random_state=None, test_size=0.5,\n",
      "            train_size=0.5), 'path_to_catalogue': 'catalog/30_MVO_labelled_events_filtered.pd'},\n",
      " <features> {'path_to_config': 'config/specific/features/features_01.json', 'computation_domains': 'time spectral cepstral', 'thresholding': True, 'thresholds': [0.8, 0.8, 0.8, 0.8, 0.8]},\n",
      " <data_to_analyze> {'path_to_data': './miniseed_c', 'data_files': '*.mseed', 'reading_function': <function read_montserrat at 0x7ff69962ac10>, 'reading_arguments': {}},\n",
      " <analysis> {'n_window': 1, 'window_length': 120.0, 'delta': 100, 'bandwidth': {'f_min': [0.5], 'f_max': [25]}, 'butter_order': 2, 'spectro_window_size': 256, 'f_max': 25, 'nBands': 1}\n",
      "\n",
      "r    114\n",
      "h    107\n",
      "l    106\n",
      "t    102\n",
      "e     93\n",
      "Name: class, dtype: int64\n",
      "['r', 'e', 'l', 'h', 't'] 3\n",
      "class\n",
      "e     83\n",
      "h    105\n",
      "l     92\n",
      "r     85\n",
      "t     99\n",
      "dtype: int64\n",
      "./AAA-master/MONTSERRAT/catalog/30_MVO_labelled_events_filtered.pd\n",
      "\n",
      "\n",
      " *** ANALYZER ***\n",
      "Training data have been read and features have been extracted  (464, 96)\n",
      "Computation time for reading and feature computation:  6.3894877433776855\n",
      "Model will be trained on 5 classes [0 1 2 3 4] ['e' 'h' 'l' 'r' 't']\n",
      "Features have been scaled\n",
      "Model has been trained:  RandomForestClassifier(criterion='entropy')\n",
      "Computation time:  0.08931303024291992\n",
      "Model score is:  0.226293103448\n",
      "and associated confusion matrix is:\n",
      "          Predicted class\n",
      "              e     h     l     r     t \n",
      "        e          83                   \n",
      "        h         105                   \n",
      "        l          92                   \n",
      "        r          85                   \n",
      "        t          99                   \n",
      "StratifiedShuffleSplit(n_splits=50, random_state=None, test_size=0.5,\n",
      "            train_size=0.5)\n",
      "Cross-validation results:  22.6034482759  +/-  0.213959890448  %\n",
      "          Predicted class\n",
      "              e     h     l     r     t \n",
      "        e          41                   \n",
      "        h          52                   \n",
      "        l          46                   \n",
      "        r          43                   \n",
      "        t          50                   \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0381ed1bec0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbatim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbatim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatalog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                     \u001b[0mallData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallPredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallProbabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbatim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbatim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# If you want the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc_mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "### PREPARE THE CATALOG DataFrame ###\n",
    "SEISAN_DATA = os.path.join( os.getenv('HOME'),'DATA','MVO') # e.g. /home/user/seismo\n",
    "pandaSeisDir = os.path.join(SEISAN_DATA, 'miniseed_c') # e.g. /home/user/seismo/pandaSeis\n",
    "SEISAN_DB = 'MVOE_' # e.g. the seisan database name (e.g. MVOE_)\n",
    "PROJECTDIR = os.path.join(os.getenv('HOME'),'src', 'kitchensinkGT', 'PROJECTS', 'MontserratML') # this dir\n",
    "#csvfile_external = os.path.join(PROJECTDIR, 'MVO_labelled_events.csv')\n",
    "csvfile_external = os.path.join(SEISAN_DATA, 'MachineLearning', SEISAN_DB, 'runAAA', 'MVOE_11_labelled_events.csv')\n",
    "#csvfile_internal = './catalog/MVO_labelled_events_filtered.csv'\n",
    "csvfile_internal = 'catalog/30_MVO_labelled_events_filtered.csv' # has to match that in AAA-master/config/general/newsettings_10.json\n",
    "csvfile_internal = './AAA-master/MONTSERRAT/' + csvfile_internal\n",
    "output_path_cat = csvfile_internal.replace('.csv', '.pd')\n",
    "alltraces_file = '30_alltraceDFs.csv'\n",
    "\n",
    "################################\n",
    "# Machine learning and testing #\n",
    "################################\n",
    "import sys\n",
    "sys.path.insert(0, './AAA-master/automatic_processing')\n",
    "#import tools\n",
    "from config import Config\n",
    "from analyzer_all_traces import Analyzer\n",
    "\n",
    "# Change if you want your screen to keep quiet\n",
    "# 0 = quiet\n",
    "# 1 = in between\n",
    "# 2 = detailed information\n",
    "verbatim = 1\n",
    "\n",
    "# Init project with configuration file\n",
    "config = Config('./AAA-master/config/general/newsettings_10.json', verbatim=verbatim)\n",
    "config.readAndCheck()  \n",
    "\n",
    "##########################\n",
    "# Variables to loop over #\n",
    "##########################\n",
    "alltraces = pd.read_csv(alltraces_file)\n",
    "minWeights = [3]\n",
    "classes_to_include = [ ['r', 'e', 'l', 'h', 't'] ]\n",
    "\n",
    "\n",
    "#############\n",
    "# Functions #\n",
    "#############\n",
    "\n",
    "def cat_filter_classes(cat, remove_classes):\n",
    "    \"\"\"\n",
    "    for rmclass in remove_classes:\n",
    "        print('Removing %s' % rmclass)\n",
    "        cat = cat[cat['class']!=rmclass]\n",
    "    \"\"\"\n",
    "    cat=cat[cat[\"class\"].isin(remove_classes)]\n",
    "    N = len(cat.index)\n",
    "    #print('%d events after removing classes' % N)\n",
    "    return cat, N\n",
    "\n",
    "def cat_filter_weight(cat, minWeight):\n",
    "    #if minWeight>0:\n",
    "    #    cat = cat[cat['weight']>=minWeight]\n",
    "    cat=cat[cat[\"weight\"].isin(range(minWeight,13))]\n",
    "    N = len(cat.index)\n",
    "    #print('%d events after filtering above %d' % (N, minWeight))\n",
    "    return cat, N\n",
    "\n",
    "def cat_check_numbers(cat, minthresh = 20):\n",
    "    df = cat.copy()\n",
    "    tooSmall = False\n",
    "    lengths = []\n",
    "    for subclass in df['class'].unique():\n",
    "        dfs = df[df['class']==subclass]\n",
    "        N = len(dfs.index)\n",
    "        if N<minthresh:\n",
    "            tooSmall=True\n",
    "        lengths.append(N)\n",
    "    return tooSmall, lengths\n",
    "\n",
    "\n",
    "#######################\n",
    "# Looping starts here #\n",
    "#######################\n",
    "minPerClass = 20\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for combine_re in [False, True]:\n",
    "    results_list = []\n",
    "    fptr = open('./AAA-master/MONTSERRAT/current_traceID.txt','w')\n",
    "    fptr.write('*')\n",
    "    fptr.close()\n",
    "\n",
    "    for minWeight in minWeights:\n",
    "        for include_classes in classes_to_include:\n",
    "            # reload cat because we filter it down each time\n",
    "            #cat = pickle.load(open(output_path_cat,'rb'))\n",
    "            cat = pd.read_csv(csvfile_internal)\n",
    "            if combine_re:\n",
    "                cat.loc[cat['class']=='e', 'class']='r'\n",
    "                if 'e' in include_classes:\n",
    "                    include_classes.remove('e')\n",
    "\n",
    "            print(cat['class'].value_counts())\n",
    "            print(include_classes, minWeight)\n",
    "\n",
    "            results_dict = {}\n",
    "            results_dict['classes'] = ','.join(include_classes)\n",
    "            results_dict['minWeight'] = minWeight\n",
    "            cat, N = cat_filter_classes(cat, include_classes) \n",
    "            results_dict['Nclasses'] = N\n",
    "            cat, N = cat_filter_weight(cat, minWeight)\n",
    "            results_dict['Nweight'] = N\n",
    "            tooSmall, lengths = cat_check_numbers(cat, minPerClass)\n",
    "            results_dict['counts'] = str(lengths)\n",
    "\n",
    "            results_dict['acc_mean'] = None\n",
    "            results_dict['acc_std'] = None\n",
    "\n",
    "            if N>=minPerClass*len(include_classes) and not tooSmall:\n",
    "                #try:\n",
    "                    print(cat.groupby('class').size())\n",
    "                    analyzer = Analyzer(config, verbatim=verbatim, catalog=cat)\n",
    "                    allData, allLabels, acc, allPredictions, allProbabilities = analyzer.learn(config, returnData=True, verbatim=verbatim) # If you want the data\n",
    "                    print(allData.shape, allLabels.shape, acc.shape)\n",
    "                    \n",
    "                    results_dict['acc_mean'] = np.round(np.mean(acc)*100, 1)\n",
    "                    results_dict['acc_std'] = np.round(np.std(acc)*100, 1)                        \n",
    "                    cat['predicted_class'] = allLabels\n",
    "                    cat['traceID'] = traceID\n",
    "                    for i, classcol in enumerate(sorted(include_classes)):\n",
    "                        colname = 'prob_%s' % classcol\n",
    "                        cat[colname] = allProbabilities[:,i]\n",
    "                    cat.to_csv(csvfile_internal.replace('.csv','_predicted_alltraces_%s.csv'  % ''.join(include_classes))) \n",
    "            results_list.append(results_dict)\n",
    "            counter += 1\n",
    "\n",
    "    resultsDF = pd.DataFrame(results_list)\n",
    "    resultsCSV = 'results_alltraces_%s.csv' % ''.join(include_classes)\n",
    "    resultsDF.to_csv(resultsCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adolescent-characteristic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21*22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-microwave",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
