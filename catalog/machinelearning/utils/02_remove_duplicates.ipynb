{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through some bugs in 00_convert_seisandb_to_csvfiles.py, I ended up with many duplicate lines in the files like reawav_MVOE_YYYYMM.csv. \n",
    "\n",
    "This code sorts that out, and the new files are like REA_WAV_MVOE_YYYY_MM.csv\n",
    "\n",
    "It also sorts out some problems with the Seisan database, e.g. 1-many mapping from WAV files to S-files\n",
    "\n",
    "Glenn Thompson, 2021/10/27 on hal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from reawav_MVOE_YYYYMM.csv files\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "SEISAN_DATA = os.path.join( os.getenv('HOME'),'DATA','MVO')\n",
    "SEISAN_DB = 'MVOE_'\n",
    "csvfiles = sorted(glob.glob(os.path.join(SEISAN_DATA,'reawav_' + SEISAN_DB + '*.csv')))\n",
    "frames = []\n",
    "for csvfile in csvfiles:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    frames.append(df) \n",
    "dfall = pd.concat(frames, sort=True)\n",
    "dfall.drop_duplicates(inplace=True)\n",
    "#dfall.set_index('filetime', inplace=True) # we will need this later to remerge\n",
    "#dfall.sort_index(inplace=True)\n",
    "allcsv = os.path.join(SEISAN_DATA, 'reawav_%sall.csv' % SEISAN_DB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of DataFrame is 208189 \n",
      "Length after drop_duplicates is 208189 \n",
      "\n",
      "\n",
      "Match 0\n",
      "SFILE= 08-2136-38L.S200604-temp\n",
      "SFILE= 08-2136-38L.S200604\n",
      "WAV_DHMS = 08-2136-38\n",
      "Correct SFILE is 08-2136-38L.S200604\n",
      "\n",
      "\n",
      "Match 1\n",
      "SFILE= 29-1227-26L.S200604-temp\n",
      "SFILE= 29-1227-26L.S200604\n",
      "WAV_DHMS = 29-1227-26\n",
      "Correct SFILE is 29-1227-26L.S200604\n",
      "Length after dropping bad sfiles is 208187 \n"
     ]
    }
   ],
   "source": [
    "SEISAN_TOP = os.getenv('SEISAN_TOP')\n",
    "SEISAN_TOP = '/media/sdd1/backups/seismo' # Uncomment to use local archive on hal, rather than newton\n",
    "\n",
    "print('Length of DataFrame is %d ' % len(dfall))\n",
    "\n",
    "# with vi, i see that there are many almost duplicate rows except for rounding errors\n",
    "# let's drop duplicates based on just sfile and path (path is wavfile)\n",
    "reawavdf2 = dfall.drop_duplicates(\n",
    "    subset=['sfile','path'],\n",
    "    keep = 'last')\n",
    "print('Length after drop_duplicates is %d ' % len(reawavdf2))\n",
    "\n",
    "# Only rows left now will have unique sfile-path combinations\n",
    "\n",
    "# Now we want to deal with events that have multiple S-files, mainly because there are DSN (MVO) and ASN (SPN) WAV files,\n",
    "# with different start times\n",
    "# Find rows of reawavdf2 with a non-unique (WAVfile) path\n",
    "duplicate_rows = reawavdf2[reawavdf2.duplicated(subset=['path'])]\n",
    "incorrect_sfiles = []\n",
    "for i,thispath in enumerate(duplicate_rows['path']):\n",
    "    sameWAVdf = reawavdf2[reawavdf2['path']==thispath]\n",
    "\n",
    "    # Find correct Sfile\n",
    "    WAV_DHMS = []\n",
    "    print('\\n\\nMatch %d' %i)\n",
    "    for i2,row in sameWAVdf.iterrows():\n",
    "        print('SFILE=',row['sfile'])\n",
    "        wavpath = os.path.join(SEISAN_TOP, row['path'])\n",
    "        readir = os.path.join(SEISAN_TOP, os.path.dirname(row['path']).replace('WAV','REA'))\n",
    "        sfilepath = os.path.join(readir, row['sfile'])\n",
    "        with open(sfilepath) as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if len(line)>0:\n",
    "                    if line[-1]=='6':\n",
    "                        if line[0]=='2' or line[0]=='1':\n",
    "                            WAV_DHMS.append(line[8:18])\n",
    "                        elif line[0]=='9':\n",
    "                            WAV_DHMS.append(line[5:15])\n",
    "    WAV_DHMS=sorted(WAV_DHMS)\n",
    "    print('WAV_DHMS = %s' % WAV_DHMS[0])\n",
    "    for i3,row in sameWAVdf.iterrows():    \n",
    "        if WAV_DHMS[0] in row['sfile'] and not '-temp' in row['sfile']:\n",
    "            print('Correct SFILE is %s' % row['sfile'])\n",
    "        else:\n",
    "            incorrect_sfiles.append(row['sfile'])\n",
    "    \n",
    "# Remove rows matching incorrect_sfiles from reawavdf2  \n",
    "dfall = reawavdf2[~reawavdf2['sfile'].isin(incorrect_sfiles)]\n",
    "print('Length after dropping bad sfiles is %d ' % len(dfall))\n",
    "dfall.to_csv(allcsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996 [10, 11, 12]\n",
      "1997 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "1901 [3]\n",
      "1998 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "1999 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "2000 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "2001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "2002 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "2003 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "2004 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "2005 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "2006 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "2007 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "2008 [1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "years = list(set(sorted(dfall.year)))\n",
    "for thisyear in years:\n",
    "    dfyear = dfall[dfall.year == thisyear]\n",
    "    months = list(set(sorted(dfyear.month)))\n",
    "    print(thisyear, months)\n",
    "    for thismonth in months:\n",
    "        dfyearmonth = dfyear[dfyear.month == thismonth]\n",
    "        yearmonthcsv = os.path.join(SEISAN_DATA, 'reawav_%s%4d%02d.csv' % (SEISAN_DB, thisyear, thismonth))\n",
    "        dfyearmonth.to_csv(yearmonthcsv)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
