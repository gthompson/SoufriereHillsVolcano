{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39fe136-f4f0-4e0c-9289-210354fdd6c8",
   "metadata": {},
   "source": [
    "# Stage 2: Event Classification\n",
    "\n",
    "## Waveform Features\n",
    "It is useful to compute amplitude, energy, and frequency features of each event waveform in real-time, and store them in some sort of \"database\" so these features can be exploited for automated event classification (e.g. machine learning), location (e.g. amplitude-source location), and quantification (e.g. Reduced Displacement, Magnitude).\n",
    "\n",
    "We already stored some \"whole waveform\" features, such as peak amplitude and duration, and naively converted the median peak amplitude from the set of triggered channels to a sort of \"uncalibrated magnitude\". But now we want to break down each waveform into a series of small time windows and compute more features.\n",
    "\n",
    "We will exploit the RSAM class here (class in the Object-Oriented sense) which is in lib/SAM.py (a \"Python module\"). The RSAM class is a convenient way of downsampling (raw) seismic data. The original RSAM system used 2.56s, 60s, and 600s. I prefer to use 2.56s for events, and 60s for continuous data. For each time window, the RSAM class computes the following features:\n",
    "\n",
    "- mean amplitude\n",
    "- median amplitude\n",
    "- max amplitude\n",
    "- std (same as rms after detrending) amplitude\n",
    "- mean amplitude in \"VT band\"\n",
    "- mean amplitude in \"LP band\"\n",
    "- mean amplitude in \"VLP band\"\n",
    "- base-2 logarithm of the ratio of VT to LP band amplitudes (frequency ratio ...)\n",
    "\n",
    "These are all features can be quickly computed because they can be done in the time domain. (I also have a more advanced \"Spectrograms\" module which among other things, computes a wider array of features in the frequency domain).\n",
    "\n",
    "<em>(Note, we can improve this by using correcting raw to velocity seismograms, and then computing VSAM instead of RSAM, to get corrected amplitude information, and also computing VSEM to get energy features too. But this tutorial focuses on frequency ratio for which RSAM works just as well...)</em>\n",
    "\n",
    "## Frequency ratio\n",
    "For this simple tutorial, we will break down each signal between the trigger ON and trigger OFF times into 2.56-s time windows, and compute the \"Frequency Ratio\", which is a base-2 logarithm of the amplitude ratio of the VT frequency band versus the LP frequency band:\n",
    "\n",
    "\\begin{align}\n",
    "fratio & = log_{2} \\frac {A_{VT}}{A_{LP}} \\\\\n",
    "\\end{align}\n",
    "\n",
    "                                                                        (Rodgers et al., 2016)\n",
    "\n",
    "We use the following definitions of the VT and LP bands:\n",
    "\n",
    "<table border=1>\n",
    "    <tr><td>Class</td><td>Frequency Band (Hz)</td></tr>\n",
    "    <tr><td>LP</td><td>0.8 - 4.0</td></tr>\n",
    "    <tr><td>VT</td><td>4.0 - 18.0</td></tr>\n",
    "</table>\n",
    "\n",
    "This means if the duration (trigger OFF - trigger ON time) of a signal is 25.6 s, and we use 6 channels, we get 60 separate measurements of frequency ratio. The time evolution of the signal is important in deciding if the signal is a hybrid, because a hybrid has a VT onset and an LP coda.\n",
    "\n",
    "## Classification\n",
    "\n",
    "Remember that MVO assigned (sub)classes are:\n",
    "<table>\n",
    "    <tr><th>subclass</th><th>description</th></tr>\n",
    "    <tr><td>'t'</td><td>Volcano-tectonic earthquake (\"VT\")</td></tr>    \n",
    "    <tr><td>'h'</td><td>Hybrid earthquake (VT onset, LP coda)</td></tr>\n",
    "    <tr><td>'l'</td><td>Long-period earthquake (\"LP\")</td></tr>\n",
    "    <tr><td>'r'</td><td>Rockfall signal. There is a continuum between dome-collapse-derived rockfalls and pyroclastic flows.</td></tr>    \n",
    "    <tr><td>'e'</td><td>LP-rockfall (probably a pyroclastic flow)</td></tr> \n",
    "</table>\n",
    "\n",
    "\n",
    "We will run a very simplistic (and unreliable!) event classifier from the vsmTools package. This uses frequency ratio and amplitude information (both from the RSAM object):\n",
    "\n",
    "For each 2.56s time window, for each channel, get a vote based on:\n",
    "<table>\n",
    "    <tr><th>fratio</th><th>subclass</th></tr>\n",
    "    <tr><th>> 0.0</th><th>VT ('t')</th></tr>    \n",
    "    <tr><th>-1.0 to 0.0</th><th>Hybrid ('h')</th></tr>\n",
    "    <tr><th>< -1.0</th><th>LP ('l')</th></tr>\n",
    "</table>\n",
    "\n",
    "For each channel, looking at patterns of amplitude and fratios (a linear regression performed for fratios):\n",
    "<table>\n",
    "    <tr><th>pattern</th><th>subclass</th></tr>\n",
    "    <tr><td>amplitude peaks early</td><td>earthquake (VT, LP, hybrid)</td></tr>    \n",
    "    <tr><td>amplitude peaks near middle</td><td>rockfall ('r')</td></tr>\n",
    "    <tr><td>fratio falling</td><td>Hybrid ('h')</td></tr>\n",
    "    <tr><td>fratio rising</td><td>LP-rockfall ('e')</td></tr>    \n",
    "</table>\n",
    "Patterns are weighted more heavily (in proportion to size of change).\n",
    "\n",
    "Signal durations are also taken into account as there is a general increase from:\n",
    "\n",
    "VT -> Hybrid -> LP ----> rockfall ----> LP-rockfall \n",
    "\n",
    "## Examples:\n",
    "1. We compute the frequency ratios for 1 event.\n",
    "2. We compute the frequency ratios for each event in the catalog.\n",
    "\n",
    "We will use the catalog we just generated from 10 days of continuous MVO seismic data, and see how the frequency ratio changes before and after the large dome collapse that began at 02:00 UTC on 13th July 2003.\n",
    "\n",
    "### Reload catalog\n",
    "\n",
    "First, we will load the catalog from the previous notebook (this might take a few tens of seconds because it has to parse over 4000 events from the QuakeML file):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2a938-a5d6-4f2e-ae19-41d4be177fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import obspy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # turn off warnings about Miniseed file encoding (and anything else!)\n",
    "sys.path.append('lib')\n",
    "import vsmTools\n",
    "\n",
    "DATA_DIR = os.path.join('data')\n",
    "EVENTS_DIR = os.path.join(DATA_DIR, 'events')\n",
    "CATALOG_DIR = os.path.join(DATA_DIR,'catalogs')\n",
    "\n",
    "catObj = vsmTools.load_catalog(CATALOG_DIR,'catalog_MV_20030712')\n",
    "print(catObj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac04628-0975-451a-8705-c4bcc6b012dc",
   "metadata": {},
   "source": [
    "### Convert catalog object to a pandas DataFrame\n",
    "Again we convert the VolcanoSeismicCatalog object to a dataframe, since this is easy to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1264aa4-6221-4135-90eb-44e7c8b66ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "catDF = catObj.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070e308b-4dba-48cd-8e01-6c5ba3f513da",
   "metadata": {},
   "source": [
    "## Example 1: Compute  the frequency ratio for 1 event\n",
    "\n",
    "We are leveraging the RSAM class here, more on this later, it is just a convenient way to downsample data and compute some features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e77c78-5e49-4277-ae12-8dde8850b3df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from SAM import RSAM\n",
    "def compute_fratio(st, evtime, duration, plot_streams=False, sampling_interval=2.56):\n",
    "    trigger_delay=2 # based on one hybrid, trigger seems to be delayed about 2-s\n",
    "    for tr in st:\n",
    "        tr.stats['units'] = 'Counts'\n",
    "    st.detrend('linear')\n",
    "    st.trim(starttime=evtime-trigger_delay, endtime=evtime+duration)\n",
    " \n",
    "    # Generate an RSAM object\n",
    "    rsamObj = RSAM(stream=st, sampling_interval=sampling_interval)\n",
    "            \n",
    "    dfratio = pd.DataFrame()\n",
    "    for i, seed_id in enumerate(rsamObj.dataframes):\n",
    "        df = rsamObj.dataframes[seed_id]\n",
    "        if i==0:\n",
    "            dfratio['datetime'] = [obspy.core.UTCDateTime(t).datetime for t in df['time']]\n",
    "        dfratio[seed_id] = df['fratio']\n",
    "    dfratio['mean'] = dfratio.mean(axis=1, numeric_only=True)\n",
    "    #print(f\"Average Frequency Ratio for whole event: {dfratio['mean'].mean():.1f}\")\n",
    "\n",
    "    return rsamObj, dfratio\n",
    "\n",
    "SAMPLING_INTERVAL = 2.56\n",
    "\n",
    "# read the 1000'th event in the catalog\n",
    "eventIndex = 2200\n",
    "row = catDF.iloc[eventIndex]\n",
    "print(row)\n",
    "this_trig = catObj.triggers[eventIndex]\n",
    "evtime = obspy.UTCDateTime(row['datetime'])\n",
    "print(evtime)\n",
    "\n",
    "# load corresponding miniseed file\n",
    "year = evtime.strftime('%Y')\n",
    "month = evtime.strftime('%m')\n",
    "duration = row['duration']\n",
    "mseedfile = os.path.join(EVENTS_DIR, 'WAV', 'MV', year, month, row['filename'] + '.mseed')\n",
    "st = obspy.read(mseedfile, 'MSEED')\n",
    "\n",
    "# plot Stream (just final Trace)\n",
    "st[-1].plot()\n",
    "\n",
    "# now cut off the pretrig and posttrig windows - this is the actual waveform that triggered\n",
    "st2 = st.copy().trim(starttime=evtime-2, endtime=evtime+row['duration'])\n",
    "st2[-1].plot()\n",
    "\n",
    "# compute and plot frequency ratio\n",
    "rsamObj, dfratio = compute_fratio(st, evtime, duration, plot_streams=True, sampling_interval=SAMPLING_INTERVAL)\n",
    "dfratio.plot(x='datetime', style='-o', ylabel='Frequency Ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b93ce99-af76-4041-9c6e-3d52e21add96",
   "metadata": {},
   "source": [
    "Note the duration of the event was only 9.3s so we only had 3 complete 2.56s windows (4 total). Longer events are more interesting for frequency ratio analysis! Nevertheless, we can see from the waveform it appears to a hybrid event (VT onset, LP coda). And if we run a far-too-simplistic classification function from the vsmTools package, we also get hybrid ('h') as the most likely answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f38a2-4c0e-4cd8-93c1-c36d4ce98484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vsmTools import classify_event\n",
    "\n",
    "subclass = classify_event(dfratio, rsamObj, this_trig, sampling_interval=SAMPLING_INTERVAL)\n",
    "print(subclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6702e8e4-3661-46c4-888b-6e4fe15b1019",
   "metadata": {},
   "source": [
    "## Example 2: Compute the frequency ratios and guess subclass for each event in the catalog\n",
    "\n",
    "<b>Warning!</b> This part takes 4-5 minutes to run on my office Linux PC. This is why the code is set to load the frequency ratio dataframe from a Pickle file if that exists already. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b4816-0ec1-4888-b813-1a90859d0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfratioPickle=os.path.join(CATALOG_DIR,'dfratio_MV_20030712.pkl')\n",
    "\n",
    "if os.path.isfile(dfratioPickle):\n",
    "    dfratio_all = pd.read_pickle(dfratioPickle)\n",
    "    catObj = vsmTools.load_catalog(CATALOG_DIR,'catalog_MV_20030712_with_subclasses')\n",
    "else:\n",
    "    # process events\n",
    "    subclasses = []\n",
    "    dfratio_all = None\n",
    "    prevYmdh = '0000/00/00 00:00'\n",
    "\n",
    "    for index, row in catDF.iterrows():\n",
    "        evtime = obspy.UTCDateTime(row['datetime'])\n",
    "        duration = row['duration']\n",
    "        Ymdh = evtime.strftime('%Y/%m/%d %H:00')\n",
    "        if Ymdh > prevYmdh:\n",
    "            print(f'Processing {Ymdh} ...')\n",
    "            prevYmdh = Ymdh\n",
    "        mseedfile = os.path.join(EVENTS_DIR, 'WAV', 'MV', Ymdh[0:4], Ymdh[5:7], row['filename'] + '.mseed')    \n",
    "        st = obspy.read(mseedfile, format='MSEED')\n",
    "        rsamObj, dfratio = compute_fratio(st, evtime, duration, sampling_interval=SAMPLING_INTERVAL)\n",
    "\n",
    "        this_trig = catObj.triggers[index]\n",
    "\n",
    "        try: \n",
    "            subclass = classify_event(dfratio, rsamObj, this_trig, sampling_interval=SAMPLING_INTERVAL)\n",
    "            subclasses.append(subclass)\n",
    "        except:\n",
    "            subclasses.append('n')\n",
    "        #print(subclasses)\n",
    "        \n",
    "        if len(dfratio)==0:\n",
    "            dfratio_all = dfratio\n",
    "        else:\n",
    "            dfratio_all = pd.concat([dfratio_all, dfratio])\n",
    "    catObj.classifications = subclasses\n",
    "    catObj.save(CATALOG_DIR,'catalog_MV_20030712_with_subclasses')\n",
    "    dfratio_all.to_pickle(dfratioPickle)\n",
    "catDF = catObj.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c0c03-6ac6-4a74-a2e6-783f2ac5f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subclass in ['r', 'e', 'l', 'h', 't']:\n",
    "    print(subclass, catObj.classifications.count(subclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299fbcb-3246-40a0-82a0-d00ca15daf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subclass in ['r', 'e', 'l', 'h', 't']:\n",
    "    mask = (catDF['classification'] == subclass)\n",
    "    df = catDF.loc[mask]\n",
    "    print('\\n\\n', subclass)\n",
    "    vsmTools.plot_eventrate(df, binsize=pd.Timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41058284-33c5-47d8-9b1f-44d36b21d665",
   "metadata": {},
   "source": [
    "According to this simplistic classifier which uses frequency ratio and amplitude data (and trends in both), most of the events are 'r' (block and ash rockfalls -> pyroclastic flows) or 'h' (hybrid earthquakes). This makes sense because the drumbeats are a hybrid earthquake swarm related to dome growth, and we know the dome collapses too in a series of block and ash flows. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41318652-f184-4617-aaee-46df83232b1b",
   "metadata": {},
   "source": [
    "## Plot frequency ratio and magnitude versus time\n",
    "\n",
    "OK, remember in the presentation where we saw the drop in frequency ratio in the continuous data ~18 hours prior to the phreatic explosion at Whakaari? Well, <b>we see a similar result here in the event data!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3519f1c-01e5-4426-8ac0-12b77c091c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dfratio_rolling = dfratio_all.copy()\n",
    "print(dfratio_all.columns)\n",
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(2,1)\n",
    "col = 'MV.MBSS..SHZ'\n",
    "dfratio_rolling.plot.scatter(ax=ax[0], x='datetime', y=col, s=0.05, rot=90, ylabel='Frequency Ratio')\n",
    "dfratio_rolling[col] = dfratio_rolling[col].rolling(30).mean()\n",
    "dfratio_rolling.plot.line(ax=ax[0], x='datetime', y=col, style='g', rot=90, ylabel='Frequency Ratio')\n",
    "ax[0].set_ylim([-2.0, 2.0])\n",
    "\n",
    "catDF.plot.scatter(ax=ax[1], x='datetime', y='magnitude', s=0.05, rot=90, ylabel='Uncalibrated Magnitude')\n",
    "catDF_rolling = catDF.copy()\n",
    "catDF_rolling['magnitude'] = catDF_rolling['magnitude'].rolling(30).mean()\n",
    "catDF_rolling.plot.line(ax=ax[1], x='datetime', y='magnitude', style='g', rot=90)\n",
    "plt.setp(ax, xlim=ax[1].get_xlim())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a07f4-98b1-401a-8506-a43fdd1f44e1",
   "metadata": {},
   "source": [
    "We observe that from around 2003/07/12 08:00, as event magnitudes increase, frequency ratios drop. \n",
    "\n",
    "That was using the 'mean' frequency ratio across the seismic network. We can also examine individual channels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5f406-7025-4ea7-aeab-d730fd3d8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "dfratio_subset= dfratio_all.loc[(dfratio_all['datetime'] >= datetime(2003,7,10, 18, 0, 0)) & (dfratio_all['datetime'] <= datetime(2003,7,15))]\n",
    "dfratio_rolling = dfratio_subset.copy()\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "for col in dfratio_all.columns:\n",
    "    if col[0:2]=='MV':\n",
    "        network, station, location, channel = col.split('.')\n",
    "        dfratio_rolling[col] = dfratio_rolling[col].rolling(300).mean()\n",
    "        dfratio_rolling.plot.line(ax=ax1, x='datetime', y=col, rot=90, ylabel='Frequency Ratio', label=station)\n",
    "        ax1.set_ylim([-3.0, 2.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3156798c-4c33-4852-b280-d299a7b3da75",
   "metadata": {},
   "source": [
    "All show a similar pattern, but we also see different biases, likely due to local site effects. Also, we have not (yet) instrument corrected the data, but we have only two types of instrument, so probably that is not the main reason for different behaviour."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
